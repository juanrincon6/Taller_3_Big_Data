####################### BOOSTING MODELS #######################

#--- Limpiar entorno
rm(list = ls())
gc()
closeAllConnections()

#--- Cargar librerías
if (!require("pacman")) install.packages("pacman")
library(pacman)

p_load(
  tidyverse, gbm, caret
)

#--- Configurar rutas
user <- Sys.getenv("USERNAME")
if (user == "judel") {
  base_path <- "C:/Users/judel/OneDrive/Documentos/ANDES/Semestre 2/Big data/tercera parte/Taller 3/input"
} else if(user == "e125379") {
  base_path <- "C:\\Users\\e125379\\OneDrive - Mastercard\\8. Uniandes\\6. Big Data\\4. Taller 3\\1. Data\\"
}

store_path <- file.path(base_path, "stores")
pred_path  <- file.path(base_path, "predicciones")
dir.create(pred_path, recursive = TRUE, showWarnings = FALSE)

#--- Cargar datos finales
train <- readRDS(file.path(store_path, "train_full_final.rds"))
test  <- readRDS(file.path(store_path, "test_full_final.rds"))

#--- Convertir factores
train$property_type <- as.factor(train$property_type)
test$property_type  <- as.factor(test$property_type)

#--- Crear log(price)
train <- train %>% mutate(logprice = log(price))

#--- Partición interna de entrenamiento
set.seed(1011)
inTrain <- createDataPartition(y = train$logprice, p = .7, list = FALSE)
bdtrain_is <- train[inTrain, ]
bdtest_is  <- train[-inTrain, ]

#--- Variables a usar (idénticas a fmla anterior)
vars_modelo <- c(
  "surface_covered", "rooms", "bedrooms", "bathrooms",
  "property_type", "tiene_remodelado", "tiene_lujoso", "tiene_bbq",
  "tiene_balcon", "tiene_terraza", "tiene_vista", "tiene_club_house",
  "tiene_chimenea", "distancia_parque", "distancia_bus",
  "distancia_avenida_principal", "distancia_universidad",
  "distancia_policia", "distancia_restaurant", "distancia_colegio"
)

#--- Fórmula del modelo
fmla <- as.formula(paste("price ~", paste(vars_modelo, collapse = " + ")))

#--- Validación cruzada
cv10 <- trainControl(method = "cv", number = 10)

################################ GBM ################################

#--- Grid de hiperparámetros
grid_gbm <- expand.grid(
  n.trees = c(100, 200),
  interaction.depth = c(1, 3),
  shrinkage = c(0.1),
  n.minobsinnode = c(10)
)

#--- Entrenar modelo GBM
set.seed(123)
gbm_model <- train(
  fmla, data = train,
  method = "gbm",
  trControl = cv10,
  tuneGrid = grid_gbm,
  verbose = FALSE
)

#--- Predecir sobre test
y_hat_gbm <- predict(gbm_model, newdata = test)

#--- Exportar predicción
submission_gbm <- test %>%
  mutate(price = round(y_hat_gbm)) %>%
  select(property_id, price)

write_csv(submission_gbm, file.path(pred_path, "submission_gbm.csv"))

 
################################ XGBoost ################################

#--- Grid de hiperparámetros
grid_xgb <- expand.grid(
  nrounds = c(100, 200),
  max_depth = c(2, 4),
  eta = c(0.1),
  gamma = c(0),
  colsample_bytree = c(0.7),
  min_child_weight = c(10),
  subsample = c(0.7)
)

#--- Entrenar modelo XGBoost
set.seed(123)
xgb_model <- train(
  fmla, data = train,
  method = "xgbTree",
  trControl = cv10,
  tuneGrid = grid_xgb,
  verbose = 0
)

#--- Predecir sobre test
y_hat_xgb <- predict(xgb_model, newdata = test)

#--- Exportar predicción
submission_xgb <- test %>%
  mutate(price = round(y_hat_xgb)) %>%
  select(property_id, price)

write_csv(submission_xgb, file.path(pred_path, "submission_xgboost.csv"))
